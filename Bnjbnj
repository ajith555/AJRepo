# Path to the CSV file
$csvFilePath = "P:\Invision\URLPDF.csv"

# Import CSV
$urls = Import-Csv -Path $csvFilePath

# Loop through each URL
foreach ($url in $urls) {
    # Open URL in Chrome
    Start-Process "chrome.exe" -ArgumentList $url.Url

    # Wait for the download to complete
    $downloaded = $false
    $timeout = 0
    while (-not $downloaded -and $timeout -lt 30) { # Adjust timeout as needed
        Start-Sleep -Seconds 1
        $timeout++
        $downloadedFiles = Get-ChildItem -Path $env:USERPROFILE\Downloads | Where-Object { $_.LastWriteTime -gt $url.LastChecked }
        if ($downloadedFiles.Count -gt 0) {
            $downloaded = $true
        }
    }

    # Get the downloaded file name
    if ($downloaded) {
        $downloadedFiles = $downloadedFiles | Sort-Object -Property LastWriteTime -Descending
        $url.FileName = $downloadedFiles[0].Name
    } else {
        # No file downloaded, update FileName as "Error"
        $url.FileName = "Error"
    }

    # Update LastChecked time
    $url.LastChecked = [DateTime]::Now

    # Export updated URL list to CSV
    $urls | Export-Csv -Path $csvFilePath -NoTypeInformation

    # Wait for 10 seconds before moving to the next URL
    Start-Sleep -Seconds 10

    # Kill Chrome after processing every 50 URLs
    if (($urls.IndexOf($url) + 1) % 50 -eq 0) {
        # Wait for 5 seconds before killing Chrome
        Start-Sleep -Seconds 5

        # Kill Chrome
        taskkill /IM "chrome.exe" /F /T
    }
}

# Close Chrome after processing all URLs
Start-Sleep -Seconds 5
taskkill /IM "chrome.exe" /F /T
