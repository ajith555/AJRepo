# Path to the CSV file
$csvFilePath = "P:\Invision\URLZIP.csv"

# Import CSV
$urls = Import-Csv -Path $csvFilePath

# Loop through each URL
foreach ($url in $urls) {
    # Open URL in Chrome
    Start-Process "chrome.exe" -ArgumentList $url.Url

    # Wait for 30 seconds to check if the download has started
    Start-Sleep -Seconds 30

    # Check if any file has started to download within 30 seconds
    $downloadedFiles = Get-ChildItem -Path $env:USERPROFILE\Downloads | Where-Object { $_.LastWriteTime -gt $url.LastChecked } | Sort-Object -Property LastWriteTime -Descending

    if ($downloadedFiles.Count -gt 0) {
        # Wait for the download to complete
        $downloadedFile = $downloadedFiles[0]
        $startTime = Get-Date
        $timeout = New-TimeSpan -Seconds 600 # Adjust the timeout as needed
        while ((Get-Date) -lt ($startTime + $timeout) -and (Test-Path $downloadedFile.FullName -PathType Leaf)) {
            Start-Sleep -Seconds 10
        }

        # Check if the file exists after download completion
        if (Test-Path $downloadedFile.FullName -PathType Leaf) {
            # Update the CSV with the downloaded file name
            $url.FileName = $downloadedFile.Name
        } else {
            # File download failed
            $url.FileName = "Error"
        }
    } else {
        # No file started downloading within 30 seconds
        $url.FileName = "Error"
    }

    # Update LastChecked time
    $url.LastChecked = Get-Date

    # Export updated URL list to CSV
    $urls | Export-Csv -Path $csvFilePath -NoTypeInformation

    # Kill Chrome after processing every 50 URLs
    if (($urls.IndexOf($url) + 1) % 50 -eq 0) {
        # Wait for 5 seconds before killing Chrome
        Start-Sleep -Seconds 5

        # Kill Chrome
        taskkill /IM "chrome.exe" /F /T
    }
}

# Close Chrome after processing all URLs
Start-Sleep -Seconds 5
taskkill /IM "chrome.exe" /F /T
