# Path to the CSV file
$csvFilePath = "P:\Invision\URLZIP.csv"

# Import CSV
$urls = Import-Csv -Path $csvFilePath

# Loop through each URL
foreach ($url in $urls) {
    Write-Host "Processing URL: $($url.Url)"
    
    # Open URL in Chrome
    Start-Process "chrome.exe" -ArgumentList $url.Url

    # Wait for the download to complete
    $downloadedFiles = $null
    $timeout = 0
    while ($timeout -lt 30) { # Adjust timeout as needed
        Start-Sleep -Seconds 1
        $downloadedFiles = Get-ChildItem -Path $env:USERPROFILE\Downloads | Where-Object { $_.LastWriteTime -gt $url.LastChecked }
        if ($downloadedFiles.Count -gt 0) {
            break
        }
        $timeout++
    }

    # Get the downloaded file name
    if ($downloadedFiles.Count -gt 0) {
        $downloadedFiles = $downloadedFiles | Sort-Object -Property LastWriteTime -Descending
        $url.FileName = $downloadedFiles[0].Name
    } else {
        # No file downloaded, update FileName as "Error"
        $url.FileName = "Error"
    }

    # Update LastChecked time
    $url.LastChecked = Get-Date

    # Export updated URL list to CSV
    $urls | Export-Csv -Path $csvFilePath -NoTypeInformation

    # Wait for 10 seconds before moving to the next URL
    Start-Sleep -Seconds 10

    # Kill Chrome after processing every 50 URLs
    if (($urls.IndexOf($url) + 1) % 50 -eq 0) {
        # Wait for 5 seconds before killing Chrome
        Start-Sleep -Seconds 5

        # Kill Chrome
        taskkill /IM "chrome.exe" /F /T
    }
}

# Close Chrome after processing all URLs
Start-Sleep -Seconds 5
taskkill /IM "chrome.exe" /F /T
