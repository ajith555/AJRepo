# Path to the CSV file
$csvFilePath = "P:\Invision\URLPDF.csv"

# Import CSV
$urls = Import-Csv -Path $csvFilePath

# Loop through each URL
for ($i = 0; $i -lt $urls.Count; $i++) {
    # Open URL in Chrome
    Start-Process "chrome.exe" -ArgumentList $urls[$i].Url

    # Wait for the download to complete
    Start-Sleep -Seconds 5 # Adjust this time according to your download speed and file sizes

    # Get the downloaded file name
    $downloadedFile = Get-ChildItem -Path $env:USERPROFILE\Downloads | Sort-Object -Property LastWriteTime -Descending | Select-Object -First 1

    # Check if a file is downloaded successfully
    if ($downloadedFile -ne $null) {
        # Update the CSV with the downloaded file name
        $urls[$i].D = $downloadedFile.Name
    } else {
        # If no file is downloaded, update with "404 error" or "No access"
        $urls[$i].D = "404 error or No access"
    }

    # Export updated CSV
    $urls | Export-Csv -Path $csvFilePath -NoTypeInformation

    # Wait for 10 seconds before moving to the next URL
    Start-Sleep -Seconds 5

    # Kill Chrome after processing every 50 URLs
    if (($i + 1) % 50 -eq 0) {
        # Wait for 5 seconds before killing Chrome
        Start-Sleep -Seconds 5

        # Kill Chrome
        taskkill /IM "chrome.exe" /F /T
    }
}
