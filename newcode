# Path to the CSV file
$csvFilePath = "P:\Invision\URLPDF.csv"

# Import CSV
$urls = Import-Csv -Path $csvFilePath

# Loop through each URL
foreach ($url in $urls) {
    # Open URL in Chrome
    Start-Process "chrome.exe" -ArgumentList $url.Url

    # Wait for the download to complete
    Start-Sleep -Seconds 10 # Adjust this time according to your download speed and file sizes

    # Get the downloaded file name
    $downloadedFiles = Get-ChildItem -Path $env:USERPROFILE\Downloads | Where-Object { $_.LastWriteTime -gt $url.LastChecked } | Sort-Object -Property LastWriteTime -Descending

    if ($downloadedFiles.Count -gt 0) {
        # Update the CSV with the downloaded file name
        $url.FileName = $downloadedFiles[0].Name
    } else {
        # No file downloaded, update FileName as "Error"
        $url.FileName = "Error"
    }

    # Update LastChecked time
    $url.LastChecked = Get-Date

    # Export updated URL list to CSV
    $urls | Export-Csv -Path $csvFilePath -NoTypeInformation

    # Wait for 10 seconds before moving to the next URL
    Start-Sleep -Seconds 10

    # Kill Chrome after processing every 50 URLs
    if (($urls.IndexOf($url) + 1) % 50 -eq 0) {
        # Wait for 5 seconds before killing Chrome
        Start-Sleep -Seconds 5

        # Kill Chrome
        taskkill /IM "chrome.exe" /F /T
    }
}

# Close Chrome after processing all URLs
Start-Sleep -Seconds 5
taskkill /IM "chrome.exe" /F /T
